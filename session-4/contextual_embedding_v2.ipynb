{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/iti107-2024S2/blob/main/session-4/contextual_embedding_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKanFNbpTfv4"
      },
      "source": [
        "# Contextual Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8phFkS4Tfv7"
      },
      "source": [
        "One of the main drawbacks of embeddings such as Word2Vec and GloVE are that they have the same embedding for the same word regardless of its meaning in a particular context. For example, the word `rock` in `The rock concert is being held at national stadium` have a very different meaning in `The naughty boy throws a rock at the dog`.\n",
        "\n",
        "Contextual embedding such as those produced by transformers (where the modern-day large language are based on) took into account the context of the word, and different embedding is generated for the same word depending on the context."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nte0QWOZwOAw"
      },
      "source": [
        "## Install Hugging Face Transformers library\n",
        "If you are running this notebook in Google Colab, you will need to install the Hugging Face transformers library as it is not part of the standard environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JcAO5A0oVMOj"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to generate some embeddings using one of the transformer model `deberta`."
      ],
      "metadata": {
        "id": "rO0i7U9ohSGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModel, AutoTokenizer\n",
        "# Load a tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "id": "82NPCKELP2cE",
        "outputId": "0cc53b5f-c414-4bdc-8edc-4418722f04fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a language model\n",
        "model = TFAutoModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "# Tokenize the sentence\n",
        "tokens = tokenizer('The rock concert is being held at national stadium.', return_tensors='tf')\n",
        "print(tokens)\n",
        "for token in tokens['input_ids'][0]:\n",
        "    print(tokenizer.decode(token))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0qLQXtCP4yI",
        "outputId": "d10cc4b6-470c-497f-8b71-5cc23940bc7f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
            "array([[ 101, 1996, 2600, 4164, 2003, 2108, 2218, 2012, 2120, 3346, 1012,\n",
            "         102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n",
            "[CLS]\n",
            "the\n",
            "rock\n",
            "concert\n",
            "is\n",
            "being\n",
            "held\n",
            "at\n",
            "national\n",
            "stadium\n",
            ".\n",
            "[SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will pass the tokens through the model to generate embeddings.  We will take the embedding produced by the last layer."
      ],
      "metadata": {
        "id": "EdIhrOD8h0mY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Process the tokens\n",
        "embeddings_1 = model(**tokens)[0]\n",
        "print(embeddings_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5BoSbY9QBRG",
        "outputId": "72835769-b440-4493-bf31-c31534d7b6e8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[-0.11788939 -0.2113927   0.12098115 ... -0.08584853  0.30624133\n",
            "    0.1480256 ]\n",
            "  [-0.2119007  -0.44722807  0.04267938 ...  0.2376779   0.58190066\n",
            "   -0.55352634]\n",
            "  [-0.26564342 -0.31427473  0.33765164 ...  0.19100845  0.2829538\n",
            "   -0.6662007 ]\n",
            "  ...\n",
            "  [ 0.7403881  -0.0133046   0.14560933 ... -0.22076568  0.16180259\n",
            "    0.22805092]\n",
            "  [ 0.5187568   0.10377903 -0.28046018 ...  0.2582071  -0.45931965\n",
            "   -0.57033604]\n",
            "  [-0.11179692  0.27194744  0.21463615 ... -0.02214796 -0.14540192\n",
            "   -0.42742828]]], shape=(1, 12, 768), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Questions**\n",
        "\n",
        "1. What is the shape of the embeddings?\n",
        "2. Why is the shape is such?"
      ],
      "metadata": {
        "id": "pH_lvBExis_W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to find the embedding of the token 'rock' used here."
      ],
      "metadata": {
        "id": "G8io3vzuiPHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_rock1 = embeddings_1[0][2]\n",
        "print(embedding_rock1)"
      ],
      "metadata": {
        "id": "kjqUWgowiVmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now write codes to find the embeddings of the word `rock` as used in the sentence `The naughty boy throws a rock at the dog.` and `The boy throws the rock into the drain`.\n"
      ],
      "metadata": {
        "id": "3wgEKbkojDbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer('The naughty boy throws a rock at the dog.', return_tensors='tf')\n",
        "print(tokens)\n",
        "for token in tokens['input_ids'][0]:\n",
        "    print(tokenizer.decode(token))\n",
        "embeddings_2 = model(**tokens)[0]\n",
        "embedding_rock2 = embeddings_2[0][6]\n",
        "print(embedding_rock2)"
      ],
      "metadata": {
        "id": "tYUkJJh4Qhzs",
        "outputId": "b10b30e6-4f46-418c-8d47-8c39e16bf594",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=\n",
            "array([[  101,  1996, 20355,  2879, 11618,  1037,  2600,  2012,  1996,\n",
            "         3899,  1012,   102]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], dtype=int32)>}\n",
            "[CLS]\n",
            "the\n",
            "naughty\n",
            "boy\n",
            "throws\n",
            "a\n",
            "rock\n",
            "at\n",
            "the\n",
            "dog\n",
            ".\n",
            "[SEP]\n",
            "tf.Tensor(\n",
            "[-1.84490643e-02  1.40414923e-01 -5.92978776e-01 -1.90066323e-01\n",
            "  2.98672557e-01 -5.65375507e-01  2.29240373e-01  4.28549826e-01\n",
            " -1.69967264e-01  4.22681034e-01 -2.03460813e-01 -2.42989957e-01\n",
            " -1.59345537e-01  5.52909553e-01 -5.03683090e-01  1.65194169e-01\n",
            " -6.35739416e-04  1.91807821e-02 -2.22798109e-01  4.93561566e-01\n",
            " -1.09925024e-01 -9.26045850e-02 -3.24452490e-01 -1.67636424e-01\n",
            "  1.07115698e+00  9.11600143e-02  1.60117760e-01  7.10087717e-01\n",
            " -1.34398356e-01  4.48895246e-02  4.89737280e-02  3.60203445e-01\n",
            "  3.27645361e-01 -3.61093700e-01 -2.48873815e-01  1.24855582e-02\n",
            "  2.97447979e-01  2.05108792e-01  4.82026301e-03 -4.54611123e-01\n",
            "  1.06057733e-01 -1.16648540e-01  2.19695926e-01 -1.36173517e-01\n",
            " -6.28688484e-02 -4.78985161e-02  5.29557228e-01  1.23734996e-02\n",
            "  4.23635036e-01  6.30764514e-02 -7.43021742e-02  8.83321583e-01\n",
            " -5.70585489e-01 -3.91307473e-01 -2.80675329e-02  1.55842766e-01\n",
            " -1.44588828e-01 -5.99302530e-01 -4.25918549e-02  1.42685324e-01\n",
            "  3.58866364e-01  2.80232847e-01  2.70158798e-01 -1.75403267e-01\n",
            " -1.64888829e-01  2.69174397e-01 -3.72348130e-01  5.41019142e-01\n",
            " -7.56194174e-01 -3.44865501e-01  3.42779458e-01  1.46190792e-01\n",
            "  7.21195787e-02 -4.52092290e-01  2.02754527e-01 -3.48289877e-01\n",
            "  2.12649241e-01  3.21147218e-02  2.90489569e-02  2.50650764e-01\n",
            " -7.44713247e-02  3.29635918e-01  3.41552585e-01  2.92940557e-01\n",
            "  3.07431351e-02 -2.48275138e-02  5.85846841e-01  1.95532739e-01\n",
            " -4.91251290e-01  6.70846879e-01 -3.35589796e-01  6.64348677e-02\n",
            " -1.49630159e-01  2.40185708e-01  3.51427495e-01 -1.89796574e-02\n",
            " -3.38488743e-02  9.44198370e-02  4.68499541e-01  1.57509282e-01\n",
            "  6.15672708e-01 -1.01396573e+00  8.80312622e-02  2.80241609e-01\n",
            " -4.06160325e-01  1.74577609e-02  3.25580657e-01 -2.08470613e-01\n",
            " -3.85503888e-01  3.18617880e-01 -2.67323852e-01 -7.81901851e-02\n",
            " -1.62915289e-02 -3.46328676e-01 -5.00097334e-01  5.07611632e-02\n",
            "  1.91089183e-01  1.94230914e-01 -4.95086640e-01  3.26877952e-01\n",
            "  3.29621196e-01 -2.15740353e-01 -4.93081868e-01  2.90933639e-01\n",
            "  3.48729938e-02 -1.92176908e-01 -3.55147392e-01  2.23001927e-01\n",
            " -8.55786726e-02 -6.04985297e-01  2.29294062e-01  1.93284169e-01\n",
            "  4.32461053e-01 -4.02123481e-01 -7.18671679e-02 -8.23888332e-02\n",
            "  9.30624753e-02 -2.30007261e-01 -4.48199898e-01 -8.10785070e-02\n",
            "  3.20792764e-01  4.75974530e-02  1.12687737e-01  4.66873795e-01\n",
            "  3.74891281e-01  6.34757504e-02 -4.07252699e-01  1.15800537e-01\n",
            "  4.52729881e-01  2.36514404e-01  1.45449758e-01  3.35856974e-01\n",
            " -2.61049807e-01  1.14594452e-01 -2.20510304e-01  8.63577873e-02\n",
            " -3.19605201e-01  1.64096445e-01 -2.63258934e-01  4.58569795e-01\n",
            " -5.43938316e-02 -4.16797578e-01 -4.89472240e-01  1.50460273e-01\n",
            "  3.25364560e-01  3.59136052e-03  2.83841759e-01  1.79374978e-01\n",
            " -3.63159448e-01  1.45430967e-01 -1.93535730e-01  3.57702017e-01\n",
            "  3.48795384e-01  4.30602431e-01  2.31992930e-01 -6.52712807e-02\n",
            "  2.57625043e-01 -3.25985074e-01 -2.91676894e-02  5.41875102e-02\n",
            " -6.54210210e-01 -3.32925469e-01  4.02500451e-01  6.42677426e-01\n",
            "  4.09636647e-01  3.09328437e-01  2.72345304e-01 -2.43163168e-01\n",
            " -7.87382722e-02 -3.07753175e-01  3.62077802e-01 -8.23631734e-02\n",
            " -1.63219288e-01 -2.02588327e-02  3.84790152e-01 -6.02959216e-01\n",
            " -6.28099322e-01 -7.36137629e-01 -2.79308647e-01 -1.76395699e-02\n",
            " -2.42834136e-01 -3.84818763e-02  3.93779397e-01 -2.13621408e-02\n",
            " -6.50362849e-01  2.68423762e-02  1.69245303e-01  1.96658149e-01\n",
            " -2.40746439e-02 -1.87475339e-01 -1.94635749e-01  3.25212926e-01\n",
            "  4.92674671e-02  1.87018532e-02  5.42430207e-02  2.38550771e-02\n",
            " -9.97694433e-02 -5.19278467e-01 -5.60024306e-02  4.74228188e-02\n",
            " -6.47932410e-01  2.32987598e-01 -6.44014478e-01  1.28619671e-02\n",
            " -2.60385364e-01  1.26778769e+00  7.00005442e-02 -1.60509214e-01\n",
            "  2.28342503e-01  6.37939334e-01 -6.69836476e-02 -9.44520831e-02\n",
            "  4.68118936e-02  5.37664175e-01 -1.11037113e-01 -2.10328400e-02\n",
            " -1.84525829e-03  1.21939912e-01 -5.33389926e-01 -5.35290360e-01\n",
            " -5.19665956e-01  2.15049326e-01  5.09734631e-01  1.96807444e-01\n",
            "  6.71906173e-01 -3.99523154e-02  1.24005944e-01  1.64690465e-01\n",
            " -3.15910995e-01 -5.04244268e-02  1.67308152e-01 -7.40226030e-01\n",
            " -1.08294159e-01 -3.16272646e-01  3.83413911e-01 -2.04248667e-01\n",
            " -5.05794644e-01 -1.41148627e-01  1.47878975e-01  7.89226294e-02\n",
            " -2.37230346e-01 -1.78447142e-01  3.59200448e-01  3.41936409e-01\n",
            " -5.69047809e-01 -2.75545180e-01  1.78985596e-02  2.06020176e-01\n",
            "  6.24840856e-01  2.67501295e-01  1.21994071e-01 -1.43609822e-01\n",
            "  9.34222266e-02  6.33527875e-01 -9.03854430e-01 -4.65654641e-01\n",
            "  2.03731239e-01  5.11502743e-01 -1.85308661e-02  1.54530182e-02\n",
            "  7.92355537e-02  5.26915014e-01 -1.19997585e+00  6.29243702e-02\n",
            "  3.51932883e-01 -2.94646621e-01  1.99298441e-01  7.14326620e-01\n",
            " -2.88903862e-01  1.67461947e-01 -2.82158822e-01  1.99441880e-01\n",
            " -3.03322047e-01  1.03841424e-02 -4.06575277e-02  1.66509062e-01\n",
            "  3.50463003e-01  1.56987995e-01  3.92140359e-01  1.90683603e-01\n",
            "  5.61328053e-01  1.46096647e-01 -7.77457878e-02 -7.22388029e-02\n",
            "  2.82947719e-01  3.69128078e-01  1.62906811e-01 -3.94615084e-01\n",
            " -4.59337044e+00  2.55909681e-01 -1.16696835e-01 -1.04094222e-01\n",
            "  4.83819395e-01  3.78432721e-01 -3.60089511e-01 -5.36270738e-01\n",
            " -7.32651114e-01  3.34809065e-01 -4.10720527e-01 -3.44372213e-01\n",
            "  4.11208987e-01  4.34039831e-01  2.95396745e-01 -3.07704091e-01\n",
            "  3.30546826e-01 -3.36906493e-01 -1.36567459e-01  7.70737767e-01\n",
            "  1.04680032e-01 -9.11255330e-02  2.55357046e-02 -1.07249115e-02\n",
            "  3.50327730e-01  3.04776847e-01  8.23533893e-01 -3.54897715e-02\n",
            "  2.57816106e-01 -2.51319885e-01  2.61162788e-01 -5.05025759e-02\n",
            "  3.19452047e-01 -6.22045636e-01  1.96128432e-02  3.53641301e-01\n",
            " -5.58353104e-02 -2.26756796e-01  1.39804706e-01 -2.05505148e-01\n",
            " -2.69747049e-01 -6.06984138e-01  7.96439946e-02  2.59484917e-01\n",
            "  3.46554428e-01 -4.01860237e-01 -1.04520783e-01 -7.90326118e-01\n",
            "  1.56918362e-01  3.70939791e-01  5.02502918e-01  1.05393194e-01\n",
            " -1.18027553e-01  8.13119933e-02  3.10047835e-01  1.02038778e-01\n",
            "  4.26763237e-01  6.56128883e-01 -3.98668528e-01 -5.70490122e-01\n",
            "  1.19782247e-01  1.06791072e-02 -6.43215358e-01 -3.91316414e-03\n",
            "  4.17036802e-01 -5.29499114e-01 -5.93979955e-01 -1.34887606e-01\n",
            " -1.45372644e-01  4.98323739e-02 -1.04255915e-01 -1.63314492e-01\n",
            "  9.71941277e-02 -8.60460699e-01  9.85825211e-02  5.05969405e-01\n",
            "  4.79975939e-01  3.82531464e-01 -2.06930727e-01  2.01336205e-01\n",
            " -5.92560709e-01 -6.07622385e-01  1.87702522e-01 -5.50024956e-02\n",
            " -2.01062620e-01 -3.50897968e-01 -1.90947592e-01 -9.44669545e-03\n",
            " -2.85194725e-01 -3.55102301e-01  1.90363392e-01 -2.07114846e-01\n",
            " -1.64531887e-01  4.58829194e-01 -2.96998732e-02  3.08767259e-01\n",
            " -2.79714823e-01 -2.78748155e-01  1.77169070e-01 -1.42419804e-02\n",
            "  1.98163196e-01  5.38665175e-01  2.63505369e-01 -1.69323266e-01\n",
            " -2.81678259e-01 -8.89906958e-02 -3.19444835e-01 -1.08371638e-01\n",
            "  7.52136298e-03  7.15237930e-02  2.98377335e-01  2.58157235e-02\n",
            "  2.29285434e-01 -2.66832709e-01 -3.71882647e-01  9.65560600e-02\n",
            " -7.29336888e-02  2.44976357e-01 -1.78739488e-01  5.23961671e-02\n",
            " -2.22373188e-01  2.59294540e-01 -1.82253525e-01 -4.18722928e-01\n",
            "  4.75546867e-02  8.02510679e-02  2.26849660e-01 -4.11616355e-01\n",
            "  4.05463696e-01 -2.23698184e-01 -3.31842750e-01  1.43128932e-01\n",
            "  1.33484736e-01  6.79522038e-01  7.10690498e-01  2.44622305e-01\n",
            " -2.94706315e-01 -3.72627199e-01 -2.87563264e-01 -5.02657369e-02\n",
            "  1.23094484e-01 -1.26827806e-01  2.07345653e-02  3.33285511e-01\n",
            " -6.18098140e-01 -9.86866876e-02 -2.82030553e-01 -4.17261124e-01\n",
            " -2.78210670e-01  2.25006044e-01 -5.90654194e-01 -2.21925676e-01\n",
            "  4.79115658e-02  1.67259723e-01  1.31165758e-02  3.09139013e-01\n",
            "  4.01789933e-01 -7.66103044e-02  3.40024143e-01 -5.90224862e-01\n",
            "  1.68131828e-01  1.06366426e-01 -1.60467222e-01  4.51474875e-01\n",
            " -5.95467448e-01  2.56930888e-01 -2.09642529e-01  2.16933414e-01\n",
            "  2.69638449e-01  5.37740402e-02 -5.53000309e-02 -4.25698191e-01\n",
            " -1.91081673e-01  6.05032206e-01 -3.94303054e-01  8.83138925e-02\n",
            "  1.11106224e-01 -4.38255161e-01 -2.69108951e-01 -6.38238788e-02\n",
            " -7.40736872e-02  6.54839128e-02  1.44653037e-01  1.07824340e-01\n",
            " -2.49008298e-01 -4.50614601e-01  1.14656255e-01  9.34497416e-02\n",
            "  2.61001199e-01 -4.25002202e-02 -1.16755694e-01  3.85576725e-01\n",
            "  3.18392426e-01  5.59253916e-02 -2.42456287e-01 -4.49070632e-01\n",
            "  2.08974123e-01  2.27011532e-01  1.37444213e-01  2.95918465e-01\n",
            " -3.62091452e-01 -3.35349321e-01  3.53213608e-01  7.71706104e-02\n",
            "  1.54489651e-01 -5.66073418e-01  5.78448474e-01 -3.35651189e-02\n",
            " -4.90335763e-01  1.48319602e-01 -2.62209833e-01 -5.92157900e-01\n",
            " -7.49100685e-01 -4.93634075e-01 -8.10221210e-02 -4.33120906e-01\n",
            " -2.08236098e-01 -5.34909606e-01  4.63679060e-03  8.92880782e-02\n",
            "  3.29338387e-03  1.76775102e-02 -3.74172106e-02 -9.96653587e-02\n",
            " -3.21891546e-01 -3.66942883e-01  2.05936044e-01  2.71169394e-01\n",
            " -6.91956580e-02  8.31746310e-02  2.43657768e-01 -1.19429028e+00\n",
            " -3.14092934e-01  2.77795583e-01  3.81609276e-02  3.44073385e-01\n",
            " -3.55418772e-01 -1.09341986e-01 -2.38558471e-01 -1.40962020e-01\n",
            "  1.19641796e-01  1.23868592e-01 -1.81865528e-01  5.33785522e-02\n",
            "  1.50569633e-01 -2.56341100e-01 -2.30632871e-01  7.46765971e-01\n",
            " -5.45666635e-01 -3.98089349e-01  4.19837892e-01  4.06950414e-01\n",
            " -1.44365042e-01 -6.48352355e-02 -3.88706699e-02 -6.53807402e-01\n",
            " -2.32810557e-01 -1.11272916e-01  3.32625598e-01  5.19593120e-01\n",
            "  1.85115010e-01 -4.27063435e-01 -1.25885308e-01  5.43725252e-01\n",
            " -4.73533086e-02 -1.77106470e-01  2.12355450e-01 -3.65519449e-02\n",
            "  2.96747327e-01 -7.59202838e-02 -9.06856656e-02 -8.26198518e-01\n",
            "  3.10478300e-01 -3.36649537e-01 -7.03057349e-01  1.52344793e-01\n",
            " -5.13348222e-01 -7.94254541e-01  1.33152958e-02 -2.81881243e-01\n",
            " -4.36723053e-01  7.71517873e-01 -4.83241081e-01 -5.39973021e-01\n",
            " -3.31497967e-01  3.49775225e-01  1.60428613e-01  5.92626929e-02\n",
            " -1.36644125e-01  1.86689217e-02  9.48365778e-05  5.25487125e-01\n",
            "  8.85191783e-02 -2.49614492e-02 -7.27687553e-02  4.22349334e-01\n",
            "  8.18547130e-01  3.50032240e-01  1.42238736e-01  3.44179064e-01\n",
            " -3.69380593e-01 -1.37673989e-01  3.91035169e-01 -1.27031922e-01\n",
            " -3.23619664e-01  2.11250842e-01  1.50993213e-01  2.26882175e-02\n",
            " -2.99937606e-01  6.72892272e-01 -5.37767410e-01 -2.63983607e-01\n",
            "  1.75970942e-01  1.47461370e-01 -5.58440924e-01 -2.11015284e-01\n",
            "  2.96407193e-01 -3.20167899e-01  2.21461266e-01  6.77643120e-02\n",
            " -1.26912341e-01 -2.72441268e-01  3.38974535e-01  8.13906789e-02\n",
            "  1.39451027e-01  3.36164355e-01 -4.77070600e-01  6.97463751e-04\n",
            "  1.60461277e-01 -3.44141901e-01 -3.55050504e-01  5.83427906e-01\n",
            "  1.30618647e-01  1.50745839e-01  1.90170869e-01 -9.62475240e-02\n",
            "  2.33758882e-01  4.80124891e-01 -1.09913517e-02 -1.78684577e-01\n",
            " -2.38603681e-01  9.78080705e-02 -4.71050143e-01  5.26662707e-01\n",
            "  7.21131623e-01 -9.96348914e-03  2.18593717e-01 -3.92337382e-01\n",
            "  1.94566771e-02  3.91292483e-01  2.94351995e-01  5.79922795e-01\n",
            "  3.42418812e-03 -7.07128823e-01  5.39674222e-01 -1.21531785e-01\n",
            " -1.66935951e-01  2.34711736e-01  6.17302954e-02  6.81765497e-01\n",
            "  1.61009863e-01  3.11397552e-01  3.71369183e-01 -5.82021326e-02\n",
            " -1.89204395e-01  6.32150590e-01 -1.58898547e-01 -1.84327260e-01\n",
            " -4.21302438e-01  2.69351393e-01  6.62071645e-01 -3.46342921e-01\n",
            "  3.02767277e-01 -3.15252841e-02 -5.83575889e-02 -5.46669066e-01\n",
            " -1.11285165e-01  1.48585364e-01  1.47314563e-01  2.06595898e-01\n",
            "  6.69189513e-01  3.47270995e-01 -8.32985044e-01  2.42557421e-01\n",
            " -8.86575133e-02 -4.46760446e-01  7.10613951e-02 -1.00899175e-01\n",
            " -6.66564584e-01 -1.55187592e-01 -1.82702824e-01 -4.05914150e-02\n",
            " -7.05327392e-02  5.20623662e-03 -1.90061912e-01 -4.44549322e-01\n",
            "  1.49856001e-01  3.55117261e-01 -4.67172325e-01  1.61886916e-01\n",
            " -3.35293338e-02  4.78070140e-01 -2.54586786e-01 -2.56739140e-01\n",
            "  2.92745233e-02  3.98208760e-02  5.25305569e-02 -1.19878635e-01\n",
            " -3.91753614e-01 -4.84950691e-02  5.78101933e-01  4.38181818e-01\n",
            " -1.46876454e-01  1.19830281e-01  2.96415299e-01 -2.18743980e-01\n",
            "  2.85870999e-01 -7.45145500e-01 -2.40348041e-01 -4.02133971e-01\n",
            " -1.89030677e-01 -2.41033286e-01  6.31744564e-02  1.10628456e-03\n",
            " -1.38102219e-01 -5.18511832e-01  3.33797008e-01 -7.15077072e-02\n",
            " -3.30692023e-01 -3.03588867e-01 -1.74067959e-01 -4.92237806e-02\n",
            "  1.32699952e-01  1.43012255e-01  1.82308063e-01 -4.39950287e-01\n",
            " -3.35599840e-01  1.37380973e-01 -1.70616612e-01 -1.28449559e-01\n",
            "  5.71768761e-01  9.77938250e-03  1.28561914e-01  2.22022668e-01\n",
            "  2.14171037e-01  3.15494835e-01 -2.49049395e-01  1.40369713e-01\n",
            "  5.03038689e-02 -4.96887088e-01 -2.07431570e-01  1.34566844e-01\n",
            " -7.88918957e-02 -3.29203680e-02  2.90305465e-02 -1.18193299e-01\n",
            "  8.87705982e-02 -4.21760119e-02  3.02636981e-01  1.29374295e-01], shape=(768,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer('A big rock falls from the slope after heavy rain.', return_tensors='tf')\n",
        "print(tokens)\n",
        "for token in tokens['input_ids'][0]:\n",
        "    print(tokenizer.decode(token))\n",
        "embeddings_3 = model(**tokens)[0]\n",
        "embedding_rock3 = embeddings_3[0][3]\n",
        "print(embedding_rock3)"
      ],
      "metadata": {
        "id": "2ESGR29ukgUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's compute how similar are the embeddings to each other"
      ],
      "metadata": {
        "id": "E9JKxtJWk0TM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.losses import CosineSimilarity\n",
        "\n",
        "cos = CosineSimilarity(axis=0)\n",
        "similarity1 = cos(embedding_rock1, embedding_rock2)\n",
        "print(-similarity1)\n",
        "\n",
        "similarity2 = cos(embedding_rock2, embedding_rock3)\n",
        "print(-similarity2)\n",
        "\n"
      ],
      "metadata": {
        "id": "dWcM7DqjQ6z9",
        "outputId": "87366e86-21cf-4b88-93e1-b06f237c9439",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.59675664, shape=(), dtype=float32)\n",
            "tf.Tensor(0.81558204, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that embedding_rock2 are more similar to embedding_rock3 than with embedding_rock1."
      ],
      "metadata": {
        "id": "elwn5Tr9SrDx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Text Classification Model with DistilBert Embeddings\n",
        "\n",
        "In the previous lab, we have trained a text classification model using pretrained context-free embeddings GloVE.\n",
        "\n",
        "In this exercise, we will replace the embeddings with embeddings produced by DistilBERT model and compare the performance."
      ],
      "metadata": {
        "id": "1sKRicbAVZ8H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create the dataset\n",
        "\n",
        "Instead of using 10000 samples as before, we will just use 2000 samples for training."
      ],
      "metadata": {
        "id": "oezBA5sQWERh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "uh7XepZEZ3Ll"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# downloaded the datasets.\n",
        "test_data_url = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/imdb_test.csv'\n",
        "train_data_url = 'https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/datasets/imdb_train.csv'\n",
        "\n",
        "train_df = pd.read_csv(train_data_url)\n",
        "test_df = pd.read_csv(test_data_url)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_SIZE = 2500\n",
        "TEST_SIZE = 500\n",
        "BATCH_SIZE = 2\n",
        "\n",
        "train_df = train_df.sample(n=TRAIN_SIZE, random_state=128)\n",
        "test_df = test_df.sample(n=TEST_SIZE, random_state=128)\n",
        "\n",
        "# convert the text label to numeric label\n",
        "train_df['sentiment'] =  train_df['sentiment'].apply(lambda x: 0 if x == 'negative' else 1)\n",
        "test_df['sentiment'] =  test_df['sentiment'].apply(lambda x: 0 if x == 'negative' else 1)"
      ],
      "metadata": {
        "id": "k_uwtaepv1ie"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(train_df, test_size=0.2, random_state=128)"
      ],
      "metadata": {
        "id": "A0R8-DTZwnBZ"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = train_df['review'].to_list()\n",
        "train_labels = train_df['sentiment'].to_list()\n",
        "val_texts = val_df['review'].to_list()\n",
        "val_labels = val_df['sentiment'].to_list()\n",
        "test_texts = test_df['review'].to_list()\n",
        "test_labels = test_df['sentiment'].to_list()"
      ],
      "metadata": {
        "id": "OSgOTn5giNK8"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_texts)"
      ],
      "metadata": {
        "id": "fQN7f_7wiXmg",
        "outputId": "c13cce52-aa48-42a6-84c1-dedbb35d5e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmboqVJWTfwA"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "We will now load the DistilBert tokenizer for the pretrained model \"distillbert-base-uncased\".  This is the same as the other lab exercise."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "f5THnkPITfwA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "254eaf73-6761-49fb-9f48-f8e07b6707b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertModel: ['vocab_projector.bias', 'vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing TFDistilBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFDistilBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertModel for predictions without further training.\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, TFAutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model = TFAutoModel.from_pretrained('distilbert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_encodings = tokenizer(train_texts, padding=True, truncation=True)\n",
        "val_encodings = tokenizer(val_texts, padding=True, truncation=True)\n",
        "test_encodings = tokenizer(test_texts, padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "Rj72APmabuBr"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 16\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_encodings),\n",
        "    train_labels\n",
        ")).batch(batch_size)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(val_encodings),\n",
        "    val_labels\n",
        ")).batch(batch_size)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_encodings),\n",
        "    test_labels\n",
        ")).batch(batch_size)"
      ],
      "metadata": {
        "id": "s041QXJYi4h1"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for encoding, label in train_dataset:\n",
        "    print(encoding)\n",
        "    print(label)\n",
        "    output = model(encoding)\n",
        "    print(output[0])\n",
        "    break"
      ],
      "metadata": {
        "id": "HxOzqWLDjVK3",
        "outputId": "f2936c21-4e15-487a-c82a-41bcfe2dc016",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
            "array([[ 101, 1045, 2052, ...,    0,    0,    0],\n",
            "       [ 101, 1996, 2190, ...,    0,    0,    0],\n",
            "       [ 101, 2023, 2003, ...,    0,    0,    0],\n",
            "       ...,\n",
            "       [ 101, 2019, 5186, ...,    0,    0,    0],\n",
            "       [ 101, 1000, 7114, ...,    0,    0,    0],\n",
            "       [ 101, 1000, 4990, ...,    0,    0,    0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(16, 512), dtype=int32, numpy=\n",
            "array([[1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       ...,\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0],\n",
            "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>}\n",
            "tf.Tensor([0 1 1 0 0 1 1 1 0 1 0 0 0 1 1 1], shape=(16,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[ 0.20510897 -0.02048307  0.00196606 ... -0.13195124  0.56740284\n",
            "    0.33686063]\n",
            "  [ 0.7437506   0.01668045 -0.04088961 ...  0.15722656  0.77581644\n",
            "    0.15504575]\n",
            "  [ 0.24532312 -0.23797199  0.18643066 ... -0.04386552  0.53037524\n",
            "   -0.1493563 ]\n",
            "  ...\n",
            "  [ 0.2526188   0.1111629   0.18625496 ... -0.2999372   0.02266818\n",
            "   -0.18007219]\n",
            "  [ 0.5047112  -0.1042671   0.24382335 ...  0.25614917 -0.03424211\n",
            "   -0.12829389]\n",
            "  [ 0.4825932  -0.04205373  0.39244625 ...  0.14891887  0.07405909\n",
            "   -0.3140675 ]]\n",
            "\n",
            " [[-0.02506212 -0.3235323   0.0497772  ...  0.04040866  0.33898205\n",
            "    0.31572133]\n",
            "  [-0.29285005 -0.64260083 -0.47798085 ...  0.3228737   0.6661966\n",
            "   -0.26964435]\n",
            "  [-0.725631   -0.14314805 -0.33124873 ...  0.16771463  0.302625\n",
            "   -0.43758023]\n",
            "  ...\n",
            "  [ 0.05692494 -0.3331193   0.17502831 ... -0.11706094  0.1885716\n",
            "   -0.14753082]\n",
            "  [ 0.15105015 -0.06119568  0.23427674 ...  0.08085668 -0.05258917\n",
            "   -0.1497587 ]\n",
            "  [ 0.1649202  -0.01998948  0.4012277  ...  0.04717316 -0.08341202\n",
            "   -0.3313186 ]]\n",
            "\n",
            " [[ 0.01960784 -0.03230022  0.03439377 ...  0.09313007  0.6279923\n",
            "    0.62616473]\n",
            "  [-0.13762762 -0.2523848  -0.05708782 ... -0.13319905  1.3440983\n",
            "    0.3558059 ]\n",
            "  [-0.24637032 -0.03064851  0.14178479 ... -0.01164438  0.8394713\n",
            "    0.7028698 ]\n",
            "  ...\n",
            "  [-0.0224689   0.10319971  0.26793072 ... -0.02336029  0.03192817\n",
            "    0.07706563]\n",
            "  [ 0.19200808 -0.02252555  0.45849466 ...  0.2522982   0.02166945\n",
            "   -0.02054569]\n",
            "  [-0.07010241 -0.04990074  0.42452562 ...  0.05001824  0.27202696\n",
            "   -0.11023784]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[-0.12025709 -0.16857958 -0.15975969 ... -0.1593524   0.66530526\n",
            "    0.0034845 ]\n",
            "  [-0.4478607   0.05033346  0.01476872 ...  0.02200333  0.94824296\n",
            "    0.11579958]\n",
            "  [-0.5318014   0.0893684   0.04670205 ... -0.19501965  0.34480453\n",
            "    0.05318099]\n",
            "  ...\n",
            "  [ 0.07569755  0.1290098   0.47050166 ...  0.27885336 -0.29156274\n",
            "    0.03526738]\n",
            "  [ 0.3889305  -0.23954976  0.40365812 ... -0.12725867  0.1869562\n",
            "   -0.35123673]\n",
            "  [ 0.13353851 -0.14041449  0.6124668  ...  0.12941965 -0.04261851\n",
            "   -0.30884615]]\n",
            "\n",
            " [[-0.26814467 -0.10027082  0.06223414 ... -0.03313527  0.6436705\n",
            "    0.44733933]\n",
            "  [-0.57490367 -0.3830823  -0.1024367  ...  0.55716974  0.5460377\n",
            "   -0.36779702]\n",
            "  [-1.2799416   0.30456674  0.3596722  ... -0.30898568  0.04115833\n",
            "   -0.34244436]\n",
            "  ...\n",
            "  [ 0.11693235  0.01702549  0.3614275  ... -0.01886077 -0.02282644\n",
            "   -0.16771391]\n",
            "  [-0.07911234 -0.01203216  0.59514135 ...  0.12807974  0.08433929\n",
            "   -0.11197716]\n",
            "  [ 0.05293985 -0.14775246  0.6765039  ...  0.29206076  0.1076058\n",
            "   -0.23619212]]\n",
            "\n",
            " [[-0.08181947 -0.14982347 -0.06045909 ...  0.06516365  0.7259666\n",
            "    0.37081188]\n",
            "  [-0.56112134 -0.30345452 -0.23666726 ...  0.5912624   0.6444232\n",
            "   -0.384467  ]\n",
            "  [-0.4994386   0.02807328  0.23722494 ... -0.22356181  0.28455532\n",
            "    0.53593355]\n",
            "  ...\n",
            "  [-0.23110674  0.02037285  0.34837523 ...  0.1420952   0.13419226\n",
            "   -0.06872074]\n",
            "  [-0.04417054 -0.16947004  0.32132018 ...  0.15501581  0.22328913\n",
            "   -0.0938881 ]\n",
            "  [-0.10016591 -0.12397987  0.3823516  ...  0.19073892  0.33706117\n",
            "   -0.13130888]]], shape=(16, 512, 768), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(dataset):\n",
        "\n",
        "    embeddings = []\n",
        "    labels = []\n",
        "\n",
        "    for encoding, label in dataset:\n",
        "        output = model(encoding)\n",
        "        embeddings.append(output[0])\n",
        "        labels.append(label)\n",
        "\n",
        "    embeddings, labels = np.concatenate(embeddings), np.concatenate(labels)\n",
        "\n",
        "    return embeddings, labels"
      ],
      "metadata": {
        "id": "NyH-QjMwjDhJ"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = extract_features(train_dataset)\n",
        "X_val, y_val = extract_features(val_dataset)\n",
        "X_test, y_test = extract_features(test_dataset)"
      ],
      "metadata": {
        "id": "4CU2zBxjjF4t"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:10]"
      ],
      "metadata": {
        "id": "5JvFvm2lk6bk",
        "outputId": "d80d679c-f106-4e89-bbfb-e0a43d8a441d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 0.20510897, -0.02048307,  0.00196606, ..., -0.13195124,\n",
              "          0.56740284,  0.33686063],\n",
              "        [ 0.7437506 ,  0.01668045, -0.04088961, ...,  0.15722656,\n",
              "          0.77581644,  0.15504575],\n",
              "        [ 0.24532312, -0.23797199,  0.18643066, ..., -0.04386552,\n",
              "          0.53037524, -0.1493563 ],\n",
              "        ...,\n",
              "        [ 0.2526188 ,  0.1111629 ,  0.18625496, ..., -0.2999372 ,\n",
              "          0.02266818, -0.18007219],\n",
              "        [ 0.5047112 , -0.1042671 ,  0.24382335, ...,  0.25614917,\n",
              "         -0.03424211, -0.12829389],\n",
              "        [ 0.4825932 , -0.04205373,  0.39244625, ...,  0.14891887,\n",
              "          0.07405909, -0.3140675 ]],\n",
              "\n",
              "       [[-0.02506212, -0.3235323 ,  0.0497772 , ...,  0.04040866,\n",
              "          0.33898205,  0.31572133],\n",
              "        [-0.29285005, -0.64260083, -0.47798085, ...,  0.3228737 ,\n",
              "          0.6661966 , -0.26964435],\n",
              "        [-0.725631  , -0.14314805, -0.33124873, ...,  0.16771463,\n",
              "          0.302625  , -0.43758023],\n",
              "        ...,\n",
              "        [ 0.05692494, -0.3331193 ,  0.17502831, ..., -0.11706094,\n",
              "          0.1885716 , -0.14753082],\n",
              "        [ 0.15105015, -0.06119568,  0.23427674, ...,  0.08085668,\n",
              "         -0.05258917, -0.1497587 ],\n",
              "        [ 0.1649202 , -0.01998948,  0.4012277 , ...,  0.04717316,\n",
              "         -0.08341202, -0.3313186 ]],\n",
              "\n",
              "       [[ 0.01960784, -0.03230022,  0.03439377, ...,  0.09313007,\n",
              "          0.6279923 ,  0.62616473],\n",
              "        [-0.13762762, -0.2523848 , -0.05708782, ..., -0.13319905,\n",
              "          1.3440983 ,  0.3558059 ],\n",
              "        [-0.24637032, -0.03064851,  0.14178479, ..., -0.01164438,\n",
              "          0.8394713 ,  0.7028698 ],\n",
              "        ...,\n",
              "        [-0.0224689 ,  0.10319971,  0.26793072, ..., -0.02336029,\n",
              "          0.03192817,  0.07706563],\n",
              "        [ 0.19200808, -0.02252555,  0.45849466, ...,  0.2522982 ,\n",
              "          0.02166945, -0.02054569],\n",
              "        [-0.07010241, -0.04990074,  0.42452562, ...,  0.05001824,\n",
              "          0.27202696, -0.11023784]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[-0.08197391, -0.16748579, -0.03765757, ...,  0.03895832,\n",
              "          0.47380942,  0.44723985],\n",
              "        [-0.38348094,  0.02084881,  0.69960773, ...,  0.07777905,\n",
              "          0.49328113,  0.46502754],\n",
              "        [-0.81049705, -0.36875373,  0.4973072 , ..., -0.02896968,\n",
              "          0.5179957 ,  0.24638033],\n",
              "        ...,\n",
              "        [ 0.14103395, -0.16019833,  0.34172428, ...,  0.23555425,\n",
              "         -0.03275282, -0.16095978],\n",
              "        [ 0.05041795, -0.05521207,  0.37858015, ...,  0.05282489,\n",
              "         -0.00893758,  0.01430161],\n",
              "        [ 0.26839125, -0.15310784,  0.55482966, ...,  0.40332794,\n",
              "         -0.02539653, -0.4959878 ]],\n",
              "\n",
              "       [[ 0.01456766, -0.05435979,  0.02723419, ..., -0.3290554 ,\n",
              "          0.57514054,  0.35925496],\n",
              "        [ 0.4329432 , -0.16583379,  0.10253882, ..., -0.11938813,\n",
              "          0.7250552 ,  0.26378283],\n",
              "        [-0.27035394, -0.02126039,  0.3193056 , ..., -0.26799756,\n",
              "          0.13245845, -0.42755806],\n",
              "        ...,\n",
              "        [ 0.16412207,  0.00568985,  0.2574575 , ..., -0.1081097 ,\n",
              "          0.20123947, -0.09313877],\n",
              "        [ 0.23669359, -0.135102  ,  0.10518162, ...,  0.12753043,\n",
              "          0.08423501, -0.12039115],\n",
              "        [ 0.15594967, -0.03355111,  0.42977744, ...,  0.02658214,\n",
              "          0.24453688, -0.2555859 ]],\n",
              "\n",
              "       [[-0.12835753, -0.20955095,  0.0104403 , ..., -0.06118169,\n",
              "          0.66452795,  0.3321464 ],\n",
              "        [-0.5422534 , -0.36008468,  0.20856136, ...,  0.01260846,\n",
              "          1.2362441 , -0.09702649],\n",
              "        [-0.5130554 ,  0.24898125, -0.2172407 , ..., -0.11016873,\n",
              "          0.2199632 , -0.11003672],\n",
              "        ...,\n",
              "        [ 0.31394303,  0.09543066,  0.3759671 , ...,  0.11263319,\n",
              "          0.04186287, -0.1602642 ],\n",
              "        [ 0.31208783,  0.10596302,  0.13311067, ..., -0.04767405,\n",
              "          0.16645665, -0.20442706],\n",
              "        [ 0.27378047, -0.17814468,  0.41364998, ...,  0.18800259,\n",
              "          0.17961924, -0.5252132 ]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVFbiO3STfwB"
      },
      "source": [
        "Here we will tokenize the text string, and pad the text string to the longest sequence in the batch, and also to truncate the sequence if it exceeds the maximum length allowed by the model (in BERT's case, it is 512)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbhAG0WnTfwD"
      },
      "source": [
        "## Train a classifier using the extracted features (embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "XiA0JMdzTfwE"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.GlobalAveragePooling1D(),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=False),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "THCqvmiNkgfO"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "root_logdir = os.path.join(os.curdir, \"tb_logs\")\n",
        "\n",
        "def get_run_logdir():    # use a new directory for each run\n",
        "\timport time\n",
        "\trun_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
        "\treturn os.path.join(root_logdir, run_id)\n",
        "\n",
        "run_logdir = get_run_logdir()\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=run_logdir)\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"bestcheckpoint.weights.h5\",\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n"
      ],
      "metadata": {
        "id": "RA8jh52Tkc8t"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    callbacks=[tensorboard_callback, model_checkpoint_callback])"
      ],
      "metadata": {
        "id": "ILtEAUpCkjii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQhBq-1sTfwE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "054ec41d-e793-4e9a-f643-5d4e7696da8b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000)</pre></div> </div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wOU0lubfFS6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b805c9b-6dbc-483e-bc5c-453368e22528"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train score : 0.90875\n",
            "test score : 0.5025\n"
          ]
        }
      ],
      "source": [
        "print(f'train score : {clf.score(X_train, y_train)}')\n",
        "# print(f'validation score : {clf.score(X_test, y_test)}')\n",
        "print(f'test score : {clf.score(X_test, y_test)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyaH5WnxTfwE"
      },
      "source": [
        "We should be getting an validation and accuracy score of around 86% to 87% which is quite good, considering we are training with only 2000 samples!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SVDxRUdTfwE"
      },
      "source": [
        "**Exercise**\n",
        "\n",
        "1. Modify the code to use the hidden states from a different attention layer as features or take average of hidden states  from few layers as features.\n",
        "2. Modify the code to use BERT model and see if it performs better than the DistilBERT. For BERT Model, the output of different layers are in `output[2]`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ohs_qdbrthxv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}